{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import sentencepiece as spm\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "column_names = ['ref', '1', '2', '3', '4', 'text']\n",
    "jorf_2023 = pd.read_csv('jorf_2023.csv', sep='|', names=column_names, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format input\n",
    "\n",
    "fraction = 0.1 # fraction of the corpus to use for training\n",
    "save_input = False # True if you want to save the input file for sentencepiece\n",
    "\n",
    "text = jorf_2023['text'].tolist()[:int(len(jorf_2023)*fraction)]\n",
    "\n",
    "if save_input:\n",
    "    with open('input.txt', 'w') as f:\n",
    "        for line in text:\n",
    "            f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/var/folders/9h/pf8tzcpd2w56l_xpcr9j2z_40000gn/T/tmpt_29gizx --model_prefix=jorf --vocab_size=1000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /var/folders/9h/pf8tzcpd2w56l_xpcr9j2z_40000gn/T/tmpt_29gizx\n",
      "  input_format: \n",
      "  model_prefix: jorf\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: /var/folders/9h/pf8tzcpd2w56l_xpcr9j2z_40000gn/T/tmpt_29gizx\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 45431 sentences\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=6879391\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9526% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=91\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999526\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 45431 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=4495907\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 89949 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 45431\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 51660\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 51660 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=34471 obj=11.402 num_tokens=124715 num_tokens/piece=3.61797\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=28927 obj=8.7369 num_tokens=125177 num_tokens/piece=4.32734\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=21679 obj=8.72836 num_tokens=131664 num_tokens/piece=6.07334\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=21648 obj=8.71132 num_tokens=131689 num_tokens/piece=6.08319\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=16235 obj=8.79402 num_tokens=142241 num_tokens/piece=8.76138\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=16235 obj=8.77295 num_tokens=142304 num_tokens/piece=8.76526\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=12176 obj=8.88884 num_tokens=154854 num_tokens/piece=12.718\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=12175 obj=8.8645 num_tokens=154852 num_tokens/piece=12.7189\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=9131 obj=9.02352 num_tokens=168852 num_tokens/piece=18.4922\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=9131 obj=8.99211 num_tokens=168853 num_tokens/piece=18.4923\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=6848 obj=9.1981 num_tokens=183553 num_tokens/piece=26.8039\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=6848 obj=9.15855 num_tokens=183554 num_tokens/piece=26.804\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=5136 obj=9.444 num_tokens=199057 num_tokens/piece=38.7572\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=5136 obj=9.39491 num_tokens=199069 num_tokens/piece=38.7595\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=3852 obj=9.72723 num_tokens=214195 num_tokens/piece=55.6062\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=3852 obj=9.66749 num_tokens=214196 num_tokens/piece=55.6064\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2889 obj=10.0611 num_tokens=230016 num_tokens/piece=79.6179\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2889 obj=9.99068 num_tokens=230733 num_tokens/piece=79.866\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2166 obj=10.4619 num_tokens=247642 num_tokens/piece=114.331\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2166 obj=10.3792 num_tokens=247650 num_tokens/piece=114.335\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1624 obj=10.9492 num_tokens=263843 num_tokens/piece=162.465\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1624 obj=10.8548 num_tokens=263857 num_tokens/piece=162.474\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1218 obj=11.5049 num_tokens=280730 num_tokens/piece=230.484\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1218 obj=11.3993 num_tokens=280732 num_tokens/piece=230.486\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1100 obj=11.6435 num_tokens=288145 num_tokens/piece=261.95\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1100 obj=11.6053 num_tokens=288145 num_tokens/piece=261.95\n",
      "trainer_interface.cc(686) LOG(INFO) Saving model: jorf.model\n",
      "trainer_interface.cc(698) LOG(INFO) Saving vocabs: jorf.vocab\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "model_prefix = 'jorf'\n",
    "\n",
    "if save_input:\n",
    "    temp_path = 'input.txt'\n",
    "\n",
    "else:\n",
    "    with tempfile.NamedTemporaryFile(delete=False, mode='w') as temp:\n",
    "        for line in text:\n",
    "            temp.write(line + '\\n')\n",
    "        temp_path = temp.name\n",
    "\n",
    "spm.SentencePieceTrainer.train(f'--input={temp_path} --model_prefix={model_prefix} --vocab_size=1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(f'{model_prefix}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Art', '.', '▁R', '.', '▁', '22', '8', '-1', '.', '▁', '—', '▁Les', '▁', 'j', 'ur', 'is', 'te', 's', '▁a', 's', 's', 'is', 't', 'ant', 's', '▁re', 'c', 'r', 'ut', 'és', '▁en', '▁application', '▁de', '▁l', \"'\", 'article', '▁L', '.', '▁', '22', '8', '-1', '▁', 'ap', 'p', 'ort', 'ent', '▁leur', '▁concours', '▁à', '▁l', \"'\", 'analyse', '▁', 'j', 'ur', 'i', 'd', 'ique', '▁des', '▁dossier', 's', '▁n', 'éc', 'es', 's', 'it', 'ant', '▁une', '▁', 'expert', 'is', 'e', '▁par', 't', 'ic', 'ul', 'ière', '▁qui', '▁leur', '▁sont', '▁con', 'f', 'i', 'és', '▁par', '▁les', '▁m', 'ag', 'is', 't', 'r', 'at', 's', '▁sous', '▁la', '▁direction', '▁des', 'quel', 's', '▁', 'il', 's', '▁sont', '▁p', 'l', 'ac', 'és', '.', '▁Il', 's', '▁sont', '▁re', 'c', 'r', 'ut', 'és', '▁en', '▁qualité', '▁d', \"'\", 'ag', 'ent', '▁contractuel', '▁de', '▁l', \"'\", 'Etat', '▁relevant', '▁de', '▁la', '▁catégorie', '▁A', '.']\n",
      "[274, 9, 107, 9, 4, 303, 89, 150, 9, 4, 46, 124, 4, 239, 125, 39, 106, 3, 37, 3, 3, 39, 13, 49, 3, 77, 31, 19, 161, 140, 33, 341, 5, 8, 6, 36, 41, 9, 4, 303, 89, 150, 4, 195, 32, 236, 52, 176, 597, 16, 8, 6, 958, 4, 239, 125, 22, 50, 153, 18, 612, 3, 71, 220, 28, 3, 67, 49, 115, 4, 922, 39, 10, 27, 13, 215, 133, 355, 127, 176, 65, 103, 78, 22, 140, 27, 20, 83, 199, 39, 13, 19, 81, 3, 290, 12, 560, 18, 392, 3, 4, 60, 3, 65, 63, 30, 112, 140, 9, 259, 3, 65, 77, 31, 19, 161, 140, 33, 493, 14, 6, 199, 52, 962, 5, 8, 6, 252, 678, 5, 12, 725, 85, 9]\n"
     ]
    }
   ],
   "source": [
    "# test encode\n",
    "\n",
    "sub_units = sp.encode_as_pieces(\"Art. R. 228-1. — Les juristes assistants recrutés en application de l'article L. 228-1 apportent leur concours à l'analyse juridique des dossiers nécessitant une expertise particulière qui leur sont confiés par les magistrats sous la direction desquels ils sont placés. Ils sont recrutés en qualité d'agent contractuel de l'Etat relevant de la catégorie A.\")\n",
    "ids = sp.encode_as_ids(\"Art. R. 228-1. — Les juristes assistants recrutés en application de l'article L. 228-1 apportent leur concours à l'analyse juridique des dossiers nécessitant une expertise particulière qui leur sont confiés par les magistrats sous la direction desquels ils sont placés. Ils sont recrutés en qualité d'agent contractuel de l'Etat relevant de la catégorie A.\")\n",
    "print(sub_units)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art. R. 228-1. — Les juristes assistants recrutés en application de l'article L. 228-1 apportent leur concours à l'analyse juridique des dossiers nécessitant une expertise particulière qui leur sont confiés par les magistrats sous la direction desquels ils sont placés. Ils sont recrutés en qualité d'agent contractuel de l'Etat relevant de la catégorie A.\n",
      "Art. R. 228-1. — Les juristes assistants recrutés en application de l'article L. 228-1 apportent leur concours à l'analyse juridique des dossiers nécessitant une expertise particulière qui leur sont confiés par les magistrats sous la direction desquels ils sont placés. Ils sont recrutés en qualité d'agent contractuel de l'Etat relevant de la catégorie A.\n"
     ]
    }
   ],
   "source": [
    "# test decode \n",
    "print(sp.decode_pieces(sub_units))\n",
    "print(sp.decode_ids(ids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
